{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AU_Hackathon-l.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhavyashahh/TapuSena/blob/master/AU_Hackathon_l.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Sfd3_sSz3mqI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install pytesseract > /dev/null 2>&1\n",
        "!sudo apt install tesseract-ocr > /dev/null 2>&1\n",
        "!pip install tesseract > /dev/null 2>&1\n",
        "!sudo apt install poppler-utils > /dev/null 2>&1\n",
        "!pip install pdf2image  > /dev/null 2>&1\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rh9xsT3r30vm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pytesseract as py\n",
        "from PIL import Image\n",
        "import pdf2image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "riUPo4DT_yTd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#converting pdf to images by libary pdf2images\n",
        "pages = pdf2image.convert_from_path('/content/gdrive/My Drive/1312.5602v1.pdf' , output_folder='/content/gdrive/My Drive/dust-bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PSLuWxcEH7dj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(type(pages))\n",
        "print(len(pages))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qQPRuLfCH-KT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install pytesseract > /dev/null 2>&1\n",
        "#doing OCR \n",
        "text=[None]*(len(pages))\n",
        "for i in range(1):\n",
        "    text[i]=py.image_to_string(pages[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hzcDoUjbfzSf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(text[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2uXDRI34eH7K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Revised Named Entity Recognition using NLTK\n",
        "word = text[0]\n",
        "result=word.find('Abstract')\n",
        "\n",
        "sentence=[None]*result\n",
        "for i in range(result):\n",
        "    sentence[i]=text[0][i]\n",
        "sentence=''.join(sentence)        #converting char array into string \n",
        "\n",
        "#here sentence is array of content upto Abstract \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mkC9ZDJMr0Uj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aN8rew4Drvt7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for sent in nltk.sent_tokenize(sentence):\n",
        "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "        if hasattr(chunk, 'label'):\n",
        "            #print(type(chunk))\n",
        "            if (chunk.label()=='PERSON'):\n",
        "                print(chunk.label(), ' '.join(c[0] for c in chunk))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PbyG7Jcfezj0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "\n",
        "doc = nlp(sentence)\n",
        "print([(X.text, X.label_) for X in doc.ents])\n",
        "type(doc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z8kWMu8cirjj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zcor6-xCi6ZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}